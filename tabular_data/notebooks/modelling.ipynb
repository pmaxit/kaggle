{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn.utils import weight_norm\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from skorch import NeuralNetClassifier, NeuralNet\n",
    "from skorch.callbacks import EpochScoring\n",
    "from skorch.callbacks import LRScheduler, EarlyStopping\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../data/tabular/train_fold.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "cat_cols = [c for c in df.columns if 'feature' in c]\n",
    "for col in cat_cols:\n",
    "    df[col]= df[col].astype('category')\n",
    "    \n",
    "cat_szs = [max(df[col]) + 1 for col in cat_cols]\n",
    "emb_szs = [(size, min(50, (size+1)//3)) for size in cat_szs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "torch.manual_seed(0)\n",
    "\n",
    "feature_dictionary_size= 360\n",
    "num_features = 75\n",
    "\n",
    "def residual_block(in_features, out_features, p_drop, non_linear = nn.ReLU(), *args, **kwargs):\n",
    "    return nn.Sequential(\n",
    "        nn.Dropout(p = p_drop),\n",
    "        weight_norm(nn.Linear(in_features, out_features)),\n",
    "        non_linear\n",
    "    )\n",
    "\n",
    "class TPSResidual(nn.Module):\n",
    "    def __init__(self, num_class = 9, emb_szs = None, dropout = 0.3, linear_nodes=32, linear_out=16, emb_output=4, num_block=3):\n",
    "        super().__init__()\n",
    "        self.num_block = num_block\n",
    "        \n",
    "        self.final_module_list = nn.ModuleList()\n",
    "\n",
    "        #self.embedding = nn.Embedding(feature_dictionary_size, emb_output)\n",
    "        self.embeds = nn.ModuleList([nn.Embedding(ni, nf) for ni,nf in emb_szs]) #type: torch.nn.modules.container.ModuleList\n",
    "        self.n_emb = sum(e.embedding_dim for e in self.embeds) # n_emb = 17 , type: int\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        self.linear = weight_norm(nn.Linear(self.n_emb, linear_nodes))\n",
    "        #self.linear = weight_norm(nn.Linear(emb_output * num_features, linear_nodes ))\n",
    "\n",
    "        for res_num in range(self.num_block):\n",
    "            self.non_linear = nn.ELU() if res_num %2 else nn.ReLU()\n",
    "            self.lin_out = linear_out if res_num == (self.num_block - 1) else linear_nodes\n",
    "            self.final_module_list.append(residual_block( self.n_emb + (res_num + 1) * linear_nodes, \n",
    "                                self.lin_out, dropout, self.non_linear))\n",
    "        self.out = nn.Linear(linear_out, num_class)\n",
    "\n",
    "        # non-linearity - activation function\n",
    "        self.selu = nn.SELU()\n",
    "        self.dropout = nn.Dropout(p = dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Embedding\n",
    "        if self.n_emb != 0:\n",
    "            x = [e(x[:,i]) for i,e in enumerate(self.embeds)] #take the embedding list and grab an embedding and pass in our single row of data.        \n",
    "            x = torch.cat(x, 1) # concatenate it on dim 1 ## remeber that the len is the batch size\n",
    "            x = self.dropout(x) # pass it through a dropout layer\n",
    "        e = self.flatten(x)\n",
    "        \n",
    "        h1 = self.dropout(e)\n",
    "        h1 = self.linear(h1)\n",
    "        h1 = self.selu(h1)\n",
    "\n",
    "        ri = torch.cat((e, h1), 1)\n",
    "        for res_num in range(self.num_block):\n",
    "            rx = self.final_module_list[res_num](ri)\n",
    "            ri = torch.cat((ri, rx), 1)\n",
    "        \n",
    "        return F.softmax(self.out(rx), dim =-1)\n",
    "\n",
    "lr_scheduler = LRScheduler(policy = ReduceLROnPlateau, monitor = 'valid_loss', mode = 'min', patience = 3, factor = 0.1, verbose = True)\n",
    "early_stopping = EarlyStopping(monitor='valid_loss', patience = 10, threshold = 0.0001, threshold_mode='rel', lower_is_better=True)\n",
    " \n",
    "net = NeuralNetClassifier(module=TPSResidual, module__emb_szs=emb_szs,\n",
    "                          device = device, lr = 0.01, max_epochs = 50, \n",
    "                          callbacks = [lr_scheduler, early_stopping], batch_size=64\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "kfold = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
       "  module_=TPSResidual(\n",
       "    (final_module_list): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): Dropout(p=0.3, inplace=False)\n",
       "        (1): Linear(in_features=1565, out_features=32, bias=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Dropout(p=0.3, inplace=False)\n",
       "        (1): Linear(in_features=1597, out_features=32, bias=True)\n",
       "        (2): ELU(alpha=1.0)\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): Dropout(p=0.3, inplace=False)\n",
       "        (1): Linear(in_features=1629, out_features=16, bias=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (embeds): ModuleList(\n",
       "      (0): Embedding(62, 21)\n",
       "      (1): Embedding(52, 17)\n",
       "      (2): Embedding(65, 22)\n",
       "      (3): Embedding(71, 24)\n",
       "      (4): Embedding(39, 13)\n",
       "      (5): Embedding(77, 26)\n",
       "      (6): Embedding(44, 15)\n",
       "      (7): Embedding(31, 10)\n",
       "      (8): Embedding(39, 13)\n",
       "      (9): Embedding(73, 24)\n",
       "      (10): Embedding(34, 11)\n",
       "      (11): Embedding(47, 16)\n",
       "      (12): Embedding(38, 13)\n",
       "      (13): Embedding(44, 15)\n",
       "      (14): Embedding(33, 11)\n",
       "      (15): Embedding(122, 41)\n",
       "      (16): Embedding(28, 9)\n",
       "      (17): Embedding(15, 5)\n",
       "      (18): Embedding(23, 8)\n",
       "      (19): Embedding(264, 50)\n",
       "      (20): Embedding(31, 10)\n",
       "      (21): Embedding(34, 11)\n",
       "      (22): Embedding(124, 41)\n",
       "      (23): Embedding(23, 8)\n",
       "      (24): Embedding(70, 23)\n",
       "      (25): Embedding(150, 50)\n",
       "      (26): Embedding(25, 8)\n",
       "      (27): Embedding(85, 28)\n",
       "      (28): Embedding(106, 35)\n",
       "      (29): Embedding(85, 28)\n",
       "      (30): Embedding(23, 8)\n",
       "      (31): Embedding(40, 13)\n",
       "      (32): Embedding(79, 26)\n",
       "      (33): Embedding(42, 14)\n",
       "      (34): Embedding(37, 12)\n",
       "      (35): Embedding(42, 14)\n",
       "      (36): Embedding(43, 14)\n",
       "      (37): Embedding(35, 12)\n",
       "      (38): Embedding(42, 14)\n",
       "      (39): Embedding(50, 17)\n",
       "      (40): Embedding(82, 27)\n",
       "      (41): Embedding(74, 25)\n",
       "      (42): Embedding(54, 18)\n",
       "      (43): Embedding(64, 21)\n",
       "      (44): Embedding(28, 9)\n",
       "      (45): Embedding(31, 10)\n",
       "      (46): Embedding(118, 39)\n",
       "      (47): Embedding(98, 33)\n",
       "      (48): Embedding(41, 14)\n",
       "      (49): Embedding(39, 13)\n",
       "      (50): Embedding(57, 19)\n",
       "      (51): Embedding(74, 25)\n",
       "      (52): Embedding(39, 13)\n",
       "      (53): Embedding(37, 12)\n",
       "      (54): Embedding(105, 35)\n",
       "      (55): Embedding(77, 26)\n",
       "      (56): Embedding(47, 16)\n",
       "      (57): Embedding(32, 11)\n",
       "      (58): Embedding(31, 10)\n",
       "      (59): Embedding(353, 50)\n",
       "      (60): Embedding(232, 50)\n",
       "      (61): Embedding(81, 27)\n",
       "      (62): Embedding(103, 34)\n",
       "      (63): Embedding(81, 27)\n",
       "      (64): Embedding(26, 9)\n",
       "      (65): Embedding(55, 18)\n",
       "      (66): Embedding(25, 8)\n",
       "      (67): Embedding(80, 27)\n",
       "      (68): Embedding(56, 19)\n",
       "      (69): Embedding(66, 22)\n",
       "      (70): Embedding(68, 23)\n",
       "      (71): Embedding(31, 10)\n",
       "      (72): Embedding(62, 21)\n",
       "      (73): Embedding(131, 44)\n",
       "      (74): Embedding(53, 18)\n",
       "    )\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "    (linear): Linear(in_features=1533, out_features=32, bias=True)\n",
       "    (non_linear): ReLU()\n",
       "    (out): Linear(in_features=16, out_features=9, bias=True)\n",
       "    (selu): SELU()\n",
       "    (dropout): Dropout(p=0.3, inplace=False)\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = df[df['kfold'] != kfold]\n",
    "valid_df = df[df['kfold']==kfold]\n",
    "lencoder = LabelEncoder()\n",
    "\n",
    "X_train = train_df.drop(['id','target','kfold'],axis=1).values.astype('int64')\n",
    "y_train = lencoder.fit_transform(train_df['target']).astype('int64')\n",
    "y_valid = lencoder.transform(valid_df['target']).astype('int64')\n",
    "\n",
    "net.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "X_valid = valid_df.drop(['id','target','kfold'],axis=1).values.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "y_pred = net.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "metrics.accuracy_score(y_valid, )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "baf9b38691353db4aaced5eebb5c5d067bde62f8d297a23724848dd35f93e574"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
